{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\Abhishek\\Desktop\\Computer Science Texas Tech University\\Fall 2018\\CS 5341 Pattern Recognition\\Healthcare Project\\GitHub\\train_2v.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
      "0  30669    Male   3.0             0              0           No   \n",
      "1  30468    Male  58.0             1              0          Yes   \n",
      "2  16523  Female   8.0             0              0           No   \n",
      "3  56543  Female  70.0             0              0          Yes   \n",
      "4  46136    Male  14.0             0              0           No   \n",
      "\n",
      "      work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
      "0      children          Rural              95.12  18.0              NaN   \n",
      "1       Private          Urban              87.96  39.2     never smoked   \n",
      "2       Private          Urban             110.89  17.6              NaN   \n",
      "3       Private          Rural              69.04  35.9  formerly smoked   \n",
      "4  Never_worked          Rural             161.28  19.1              NaN   \n",
      "\n",
      "   stroke  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "0    42617\n",
      "1      783\n",
      "Name: stroke, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))\n",
    "# take a look at the outcome variable stroke\n",
    "print(df['stroke'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
      "0  30669    Male   3.0             0              0           No   \n",
      "1  30468    Male  58.0             1              0          Yes   \n",
      "2  16523  Female   8.0             0              0           No   \n",
      "3  56543  Female  70.0             0              0          Yes   \n",
      "4  46136    Male  14.0             0              0           No   \n",
      "\n",
      "      work_type Residence_type  avg_glucose_level   bmi   smoking_status  \n",
      "0      children          Rural              95.12  18.0              NaN  \n",
      "1       Private          Urban              87.96  39.2     never smoked  \n",
      "2       Private          Urban             110.89  17.6              NaN  \n",
      "3       Private          Rural              69.04  35.9  formerly smoked  \n",
      "4  Never_worked          Rural             161.28  19.1              NaN  \n"
     ]
    }
   ],
   "source": [
    "x = df.drop('stroke', 1)\n",
    "print(x.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: stroke, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = df['stroke']\n",
    "print(y.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 'gender' has 3 unique categories\n",
      "Feature 'ever_married' has 2 unique categories\n",
      "Feature 'work_type' has 5 unique categories\n",
      "Feature 'Residence_type' has 2 unique categories\n",
      "Feature 'smoking_status' has 4 unique categories\n"
     ]
    }
   ],
   "source": [
    "for col_name in x.columns:\n",
    "    if x[col_name].dtypes == 'object':\n",
    "        unique_cat = len(x[col_name].unique())\n",
    "        print(\"Feature '{col_name}' has {unique_cat} unique categories\".format(\n",
    "            col_name=col_name, unique_cat=unique_cat\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Private          24834\n",
      "Self-employed     6793\n",
      "children          6156\n",
      "Govt_job          5440\n",
      "Never_worked       177\n",
      "Name: work_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x['work_type'].value_counts().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id   age  hypertension  heart_disease  avg_glucose_level   bmi  \\\n",
      "0  30669   3.0             0              0              95.12  18.0   \n",
      "1  30468  58.0             1              0              87.96  39.2   \n",
      "2  16523   8.0             0              0             110.89  17.6   \n",
      "3  56543  70.0             0              0              69.04  35.9   \n",
      "4  46136  14.0             0              0             161.28  19.1   \n",
      "\n",
      "   gender_Female  gender_Male  gender_Other  ever_married_No  \\\n",
      "0              0            1             0                1   \n",
      "1              0            1             0                0   \n",
      "2              1            0             0                1   \n",
      "3              1            0             0                0   \n",
      "4              0            1             0                1   \n",
      "\n",
      "           ...            work_type_Govt_job  work_type_Never_worked  \\\n",
      "0          ...                             0                       0   \n",
      "1          ...                             0                       0   \n",
      "2          ...                             0                       0   \n",
      "3          ...                             0                       0   \n",
      "4          ...                             0                       1   \n",
      "\n",
      "   work_type_Private  work_type_Self-employed  work_type_children  \\\n",
      "0                  0                        0                   1   \n",
      "1                  1                        0                   0   \n",
      "2                  1                        0                   0   \n",
      "3                  1                        0                   0   \n",
      "4                  0                        0                   0   \n",
      "\n",
      "   Residence_type_Rural  Residence_type_Urban  smoking_status_formerly smoked  \\\n",
      "0                     1                     0                               0   \n",
      "1                     0                     1                               0   \n",
      "2                     0                     1                               0   \n",
      "3                     1                     0                               1   \n",
      "4                     1                     0                               0   \n",
      "\n",
      "   smoking_status_never smoked  smoking_status_smokes  \n",
      "0                            0                      0  \n",
      "1                            1                      0  \n",
      "2                            0                      0  \n",
      "3                            0                      0  \n",
      "4                            0                      0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "todummy_list = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "def dummy_df(df, todummy_list):\n",
    "    for X in todummy_list:\n",
    "        dummies = pd.get_dummies(df[X], prefix=X, dummy_na=False) #setting dummy_na to true means that\n",
    "        # i am creating a column named smoking_status_nan where it would be 1\n",
    "        df = df.drop(X, 1)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "x = dummy_df(x, todummy_list)\n",
    "\n",
    "print(x.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmi                      1462\n",
      "smoking_status_smokes       0\n",
      "ever_married_No             0\n",
      "age                         0\n",
      "hypertension                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x.isnull().sum().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43400, 21)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.605038390004545\n",
      "27.7\n"
     ]
    }
   ],
   "source": [
    "print(x['bmi'].mean())\n",
    "print(x['bmi'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['bmi'].fillna(x['bmi'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smoking_status_smokes    0\n",
      "ever_married_No          0\n",
      "age                      0\n",
      "hypertension             0\n",
      "heart_disease            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x.isnull().sum().sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# import sklearn.feature_selection\n",
    "# def find_outliers_tukey(X):\n",
    "#     q1 = np.percentile(X, 25)\n",
    "#     q3 = np.percentile(X, 75)\n",
    "#     iqr = q3-q1\n",
    "#     floor = q1 - 1.5*iqr\n",
    "#     ceiling = q3 + 1.5*iqr\n",
    "#     outlier_indices = list(X.index[(X < floor)|(X > ceiling)])\n",
    "#     outlier_values = list(X[outlier_indices])\n",
    "\n",
    "#     return outlier_indices, outlier_values\n",
    "# tukey_indices, tukey_values = find_outliers_tukey(x['bmi'])\n",
    "# print(\"show outliers\", np.sort(tukey_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# def plot_histogram_dv(x, y):\n",
    "#     plt.hist(list(x[y == 0]), alpha=0.5, label='DV=0')\n",
    "#     plt.hist(list(x[y == 1]), alpha=0.5, label='DV=1')\n",
    "#     plt.title(\"HIstogram of '{var_name}' by DV Category\".format(var_name=x.name))\n",
    "#     plt.xlabel(\"Value\")\n",
    "#     plt.ylabel(\"Frequency\")\n",
    "#     plt.legend(loc='upper right')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# plot_histogram_dv(x['age'], y)\n",
    "# plot_histogram_dv(x['bmi'], y)\n",
    "# plot_histogram_dv(x['hypertension'], y)\n",
    "# plot_histogram_dv(x['avg_glucose_level'], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id   age  hypertension  heart_disease  avg_glucose_level   bmi  \\\n",
      "0  30669.0   3.0           0.0            0.0              95.12  18.0   \n",
      "1  30468.0  58.0           1.0            0.0              87.96  39.2   \n",
      "2  16523.0   8.0           0.0            0.0             110.89  17.6   \n",
      "3  56543.0  70.0           0.0            0.0              69.04  35.9   \n",
      "4  46136.0  14.0           0.0            0.0             161.28  19.1   \n",
      "\n",
      "   gender_Female  gender_Male  gender_Other  ever_married_No  \\\n",
      "0            0.0          1.0           0.0              1.0   \n",
      "1            0.0          1.0           0.0              0.0   \n",
      "2            1.0          0.0           0.0              1.0   \n",
      "3            1.0          0.0           0.0              0.0   \n",
      "4            0.0          1.0           0.0              1.0   \n",
      "\n",
      "                      ...                      \\\n",
      "0                     ...                       \n",
      "1                     ...                       \n",
      "2                     ...                       \n",
      "3                     ...                       \n",
      "4                     ...                       \n",
      "\n",
      "   work_type_children_Residence_type_Urban  \\\n",
      "0                                      0.0   \n",
      "1                                      0.0   \n",
      "2                                      0.0   \n",
      "3                                      0.0   \n",
      "4                                      0.0   \n",
      "\n",
      "   work_type_children_smoking_status_formerly smoked  \\\n",
      "0                                                0.0   \n",
      "1                                                0.0   \n",
      "2                                                0.0   \n",
      "3                                                0.0   \n",
      "4                                                0.0   \n",
      "\n",
      "   work_type_children_smoking_status_never smoked  \\\n",
      "0                                             0.0   \n",
      "1                                             0.0   \n",
      "2                                             0.0   \n",
      "3                                             0.0   \n",
      "4                                             0.0   \n",
      "\n",
      "   work_type_children_smoking_status_smokes  \\\n",
      "0                                       0.0   \n",
      "1                                       0.0   \n",
      "2                                       0.0   \n",
      "3                                       0.0   \n",
      "4                                       0.0   \n",
      "\n",
      "   Residence_type_Rural_smoking_status_formerly smoked  \\\n",
      "0                                                0.0     \n",
      "1                                                0.0     \n",
      "2                                                0.0     \n",
      "3                                                1.0     \n",
      "4                                                0.0     \n",
      "\n",
      "   Residence_type_Rural_smoking_status_never smoked  \\\n",
      "0                                               0.0   \n",
      "1                                               0.0   \n",
      "2                                               0.0   \n",
      "3                                               0.0   \n",
      "4                                               0.0   \n",
      "\n",
      "   Residence_type_Rural_smoking_status_smokes  \\\n",
      "0                                         0.0   \n",
      "1                                         0.0   \n",
      "2                                         0.0   \n",
      "3                                         0.0   \n",
      "4                                         0.0   \n",
      "\n",
      "   Residence_type_Urban_smoking_status_formerly smoked  \\\n",
      "0                                                0.0     \n",
      "1                                                0.0     \n",
      "2                                                0.0     \n",
      "3                                                0.0     \n",
      "4                                                0.0     \n",
      "\n",
      "   Residence_type_Urban_smoking_status_never smoked  \\\n",
      "0                                               0.0   \n",
      "1                                               1.0   \n",
      "2                                               0.0   \n",
      "3                                               0.0   \n",
      "4                                               0.0   \n",
      "\n",
      "   Residence_type_Urban_smoking_status_smokes  \n",
      "0                                         0.0  \n",
      "1                                         0.0  \n",
      "2                                         0.0  \n",
      "3                                         0.0  \n",
      "4                                         0.0  \n",
      "\n",
      "[5 rows x 207 columns]\n"
     ]
    }
   ],
   "source": [
    "def add_intercations(df):\n",
    "    #get feature names\n",
    "    combos = list(combinations(list(df.columns), 2))\n",
    "    colnames = list(df.columns) + ['_'.join(X) for X in combos]\n",
    "\n",
    "    # Find interactions\n",
    "    poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n",
    "    df = poly.fit_transform(df)\n",
    "    df = pd.DataFrame(df)\n",
    "    df.columns = colnames\n",
    "\n",
    "    # Remove interaction terms with all 0 values\n",
    "    noint_interactions = [i for i, X in enumerate(list((df == 0).all())) if X]\n",
    "    df = df.drop(df.columns[noint_interactions],axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "x = add_intercations(x)\n",
    "print(x.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sklearn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e0b3fd9a5c8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mselect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSelectKBest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mselected_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mindices_selected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselected_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sklearn' is not defined"
     ]
    }
   ],
   "source": [
    "# such a large feature can cause overfitting and also slow computing\n",
    "# so selecting features now\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "select = sklearn.feature_selection.SelectKBest(k=20)\n",
    "selected_features = select.fit(x_train, y_train)\n",
    "indices_selected = selected_features.get_support(indices=True)\n",
    "colnames_selected = [x.columns[i] for i in indices_selected]\n",
    "\n",
    "x_train_selected = x_train[colnames_selected]\n",
    "x_test_selected = x_test[colnames_selected]\n",
    "\n",
    "print(colnames_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0             1              2             3             4  \\\n",
      "0 -1.361629e+06  1.137869e+06   -2238.199667  22513.013750  25192.302097   \n",
      "1 -9.746088e+05 -6.206867e+05  186158.163053 -21153.862043  24030.771434   \n",
      "2 -2.413072e+06  7.990916e+05 -167309.938260 -12273.831439 -10899.252959   \n",
      "3  9.714198e+05 -2.409392e+06  293117.490798  39487.407747 -24918.007690   \n",
      "4  3.107689e+06  2.058696e+06 -237563.694279  33481.392773  34355.294404   \n",
      "\n",
      "              5            6             7             8            9  \n",
      "0  16563.175623  5057.796289  -1517.376342    549.265803  4169.670711  \n",
      "1 -18845.999835  5660.556803  19735.869715  -2643.996544 -4183.085602  \n",
      "2  -5439.234620  4145.041494  -6547.351396  -1419.298416 -2976.305893  \n",
      "3  -3692.541201  1879.306007 -45390.617023 -35580.242246  6799.942625  \n",
      "4  13927.633082  6398.341538  -1028.064462    880.367477  -683.856597  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "x_pca = pd.DataFrame(pca.fit_transform(x))\n",
    "\n",
    "print(x_pca.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34720, 207) (34720,)\n",
      "(8680, 207) (8680,)\n"
     ]
    }
   ],
   "source": [
    "# create training and testing vars\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial size (43400, 12)\n",
      "after dumming and adding interactions (43400, 207)\n"
     ]
    }
   ],
   "source": [
    "# check the total no. of features grown after dummying and adding interactions terms\n",
    "print(\"initial size\", df.shape)\n",
    "print(\"after dumming and adding interactions\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_selected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e3112e590bef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mauc_processed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_model_perf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_selected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test_selected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_processed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train_selected' is not defined"
     ]
    }
   ],
   "source": [
    "def find_model_perf(x_train, y_train, x_test, y_test):\n",
    "    model = LogisticRegression(solver='lbfgs')\n",
    "    model.fit(x_train, y_train)\n",
    "    y_hat = [X[1] for X in model.predict_proba(x_test)]\n",
    "    auc = roc_auc_score(y_test, y_hat)\n",
    "\n",
    "    return auc\n",
    "\n",
    "\n",
    "auc_processed = find_model_perf(x_train_selected, y_train, x_test_selected, y_test)\n",
    "print(auc_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43400, 12)\n",
      "(29072, 12)\n",
      "0.6950559455941268\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'auc_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-55d35618dc95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m# compare model performance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AUC of model with data preprocessing: {auc}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauc_processed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AUC of model with data without preprocessing: {auc}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauc_unprocessed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mper_improve\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_processed\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mauc_unprocessed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mauc_unprocessed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'auc_processed' is not defined"
     ]
    }
   ],
   "source": [
    "# build model with unprocessed data\n",
    "# checking with the data without preprocessing\n",
    "df_unprocessed = df\n",
    "df_unprocessed = df_unprocessed.dropna(axis=0, how='any')\n",
    "print(df.shape)\n",
    "print(df_unprocessed.shape)\n",
    "\n",
    "# remove non-numeric columns so model does not throw an error\n",
    "for col_name in df_unprocessed.columns:\n",
    "    if df_unprocessed[col_name].dtypes not in ['int32', 'int64', 'float32', 'float64']:\n",
    "        df_unprocessed = df_unprocessed.drop(col_name, 1)\n",
    "\n",
    "\n",
    "# split into features and outcomes\n",
    "x_unprocessed = df_unprocessed.drop('stroke', 1)\n",
    "y_unprocessed = df_unprocessed['stroke']\n",
    "\n",
    "# how unfeature set looks like\n",
    "# print(x_unprocessed.head(5))\n",
    "\n",
    "# split unprocessed data into train and test set\n",
    "# build model and assess performance\n",
    "x_train_unprocessed, x_test_unprocessed, y_train, y_test = train_test_split(\n",
    "    x_unprocessed, y_unprocessed, test_size=0.2, random_state=1)\n",
    "\n",
    "auc_unprocessed = find_model_perf(x_train_unprocessed, y_train, x_test_unprocessed, y_test)\n",
    "print(auc_unprocessed)\n",
    "\n",
    "# compare model performance\n",
    "\n",
    "print('AUC of model with data preprocessing: {auc}'.format(auc=auc_processed))\n",
    "print('AUC of model with data without preprocessing: {auc}'.format(auc=auc_unprocessed))\n",
    "per_improve = ((auc_processed-auc_unprocessed)/auc_unprocessed)*100\n",
    "print('Model improvement of preprocessing: {per_improve}%'.format(per_improve = per_improve))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
